\documentclass{article}
\usepackage{natbib}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\DeclareMathOperator*{\Diag}{Diag}
\DeclareMathOperator*{\TPR}{TPR}
\DeclareMathOperator*{\Segments}{Segments}
\DeclareMathOperator*{\Changes}{Changes}
\DeclareMathOperator*{\FPR}{FPR}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\maximize}{maximize}
\DeclareMathOperator*{\minimize}{minimize}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\NN}{\mathbb N}
\newcommand{\RR}{\mathbb R}

\begin{document}

\title{FPOP with labels}
\author{Toby Dylan Hocking}
\maketitle

We have a sequence of $d$ data points to segment,
$\mathbf z\in\mathbb R^d$. We also have $l$ labeled regions
$R=\{(\underline p_1, \overline p_1, c_1), \dots,
(\underline p_l, \overline p_l, c_l)\}$:
\begin{itemize}
\item $\underline p_j$ is the start of a labeled region,
\item $\overline p_j$ is the end of a labeled region,
\item $c_j\in\{0,1\}$ is the number of changes in the region
  $[\underline p_j, \overline p_j]$. 
\end{itemize}
For example
$R=\{(\underline p_1=1,\overline p_1=2,c_1=0),(\underline
p_2=2,\overline p_2=5,c_2=1)\}$ means that there is no change after
the first data point, and there must be exactly one change somewhere
between data points 2 and 5 (three possibilities). Assume the
labeled regions are ordered:
\begin{equation}
  \label{eq:sorted}
  1 \leq 
\underline p_1 < \overline p_1 \leq 
\underline p_2 < \overline p_2 \leq
\cdots \leq 
\underline p_l < \overline p_l \leq 
d
\end{equation}
Thus the number of possible labels is $l\in\{0, 1, \dots, d-1\}$.

\section{Optimization problem}

We would like to find the best mean vector $\mathbf m\in\mathbb R^d$.
Best is defined using the Optimal Partitioning objective function -- a
loss $\ell$ term for each data point, and a per-change penalty of
$\lambda\geq 0$ \citep{Maidstone2016}. We also add the constraints that the
labels must be obeyed.

\begin{align}
\hat C_t = \min_{
  \mathbf m\in\RR^{t}
  } &\ \ 
\lambda\sum_{i=1}^{t-1} I(m_i \neq m_{i+1})
+
\sum_{i=1}^d \ell(z_i, m_i) 
  \label{LabeledProb}
\\
    \text{subject to} 
& \ \ \sum_{i=\underline p_j}^{\overline p_j-1} I(m_i \neq m_{i+1})=c_j
\text{ for all } j\in\{1,\dots,l\}.
\nonumber
\end{align}
Note that $I$ is the indicator function (1 if true, 0 otherwise).

SegAnnot is one algorithm that can be used in this context, but it is
limited in that it can not detect any changes that are not labeled
\citep{Hocking2012}. In fact SegAnnot computes a model with exactly
$N_1(R)=\sum_{(\underline p_j, \overline p_j, c_j)\in R} I(c_j=1)$ changes.

The labels cover
$S(R)=\sum_{(\underline p_j, \overline p_j, c_j)\in R} \overline
p_j-\underline p_j$ possible changes, in which there are exactly
$N_1(R)$ changes. There are thus $d-S(R)$ positions which are not
labeled, which may or may not have changes. Thus the number of
possible changes is in $[N_1(R), d-S(R)+N_1(R)]$.

\section{Algorithm}

We propose a new algorithm, LabeledFPOP, which solves
(\ref{LabeledProb}). We define $C_t(\mu)$ as the optimal cost up to
data point $t$ if there is a mean of $\mu$ on the last data point
$t$. The initialization is $C_1(\mu)= \ell(z_1, \mu)$. 

\subsection{Usual FPOP}
The usual FPOP algorithm does not have label constraints
\citep{Maidstone2016}. The dynamic programming update rule for $t>1$
is
\begin{equation}
  \label{eq:usual_FPOP}
  C_t(\mu)=\ell(z_t, \mu) + \min
  \begin{cases}
\hat C_{t-1}+\lambda &\text{ if there is a change between $t-1$ and $t$,}\\
C_{t-1}(\mu) & \text{ if there is no change.}
  \end{cases}
\end{equation}
Note that $\hat C_{t-1}=\min_\mu C_{t-1}(\mu)$ is the optimal cost up
to data point $t-1$.

For LabeledFPOP the update rule (\ref{eq:usual_FPOP}) is used if there
is no label between data points $t-1$ and $t$. Indeed, if $R=\{\}$
then there are no labels at all, so the LabeledFPOP problem is the
same as the usual FPOP.

\subsection{Negative label}
If there is a $c_j=0$ label such that
$t \in\{\underline p_j+1, \dots,  \overline p_j\}$, then the update rule is
simpler: the only possibility is no change.
\begin{equation}
  \label{eq:negative_update}
  C_t(\mu)=\ell(z_t,\mu)+
C_{t-1}(\mu).
\end{equation}

\subsection{Positive label at the start}
For a $c_j=1$ label the update rule is a bit more complicated. Take a
simple example to start. For a
$(\underline p_j=1,\overline p_j=3,c_j=1)$ label, the cost up to the
end of the label is
\begin{equation}
  \label{eq:positive_cost}
  \min_{\mu_1, \mu_2}
  \begin{cases}
    \lambda+\ell(z_1,\mu_1) + \ell(z_2, \mu_2)+\ell(z_3, \mu_2) &\text{ for a
      change after 1}\\
    \lambda+\ell(z_1,\mu_1) + \ell(z_2, \mu_1)+\ell(z_3, \mu_2) &\text{ for a
      change after 2}\\
  \end{cases}
\end{equation}
In general for a
$(\underline p_j=1,\overline p_j,c_j=1)$ label, the cost up to the end
of the label is
\begin{equation}
  \label{eq:positive_cost}
  \min_{\mu_1, \mu_2}
  \min_{t\in[1, \overline p_j-1]}
\lambda+
  \underbrace{
    \sum_{j=1}^t \ell(z_j, \mu_1)
  }_{\mathcal L_{1,t}(\mu_1)}+
  \underbrace{
    \sum_{j=t+1}^{\overline p_j}\ell(z_j, \mu_2)
  }_{\mathcal L_{t+1,\overline p_j}(\mu_2)}.
\end{equation}
We can use the recursive update rule for $t\in\{2,\dots, \overline p_j-1\}$:
\begin{equation}
  \mathcal L_{1,t}(\mu) = \mathcal L_{1,t-1}(\mu) +\ell(z_t , \mu).
\end{equation}
And then for the optimal cost we initialize $t=2$ to the cost of a
change between 1 and 2:
\begin{equation}
  C_2(\mu)=\mathcal{\hat L}_{1,1}+\lambda+\ell(z_2,\mu).
\end{equation}
And then
the update rule for
$t\in\{3,\dots \overline p_j\}$ is:
\begin{equation}
  \label{eq:positive_update}
  C_t(\mu)=\ell(z_t, \mu) + \min
  \begin{cases}
\mathcal{\hat L}_{1, t-1}+\lambda &\text{ if there is a change between $t-1$ and $t$,}\\
C_{t-1}(\mu) & \text{ if the labeled change was before that.}
  \end{cases}
\end{equation}
\subsection{Positive label general case}

In general for a $(\underline p_j,\overline p_j,c_j=1)$ label, we need
to compute the following quantities. First at $t=\underline p_j+1$ we
only need to consider one possibility (a change between
$t-1=\underline p_j$ and $t=\underline p_j+1$) to compute the optimal
cost function,
\begin{equation}
  \label{eq:c1init}
  C_t(\mu) = \ell(z_t, \mu) + \hat C_{t-1} + \lambda.
\end{equation}
If the label spans more than one possible changepoint
($\underline p_j+1<\overline p_j$) then for all
$t\in\{\underline p_j+1,\dots,\overline p_j-1\}$ we also need to
compute the cost of no change since the start of the label, and store
it in a separate function,
\begin{equation}
  \label{eq:c1v}
  V_t(\mu) = \ell(z_t, \mu) +
  \begin{cases}
    C_{t-1}(\mu) & \text{ if } t=\underline p_j+1,\\
    V_{t-1}(\mu) & \text{ if } t\in\{\underline p_j+2,\dots,\overline p_j-1\}.
  \end{cases}
\end{equation}
And for all $t\in\{\underline p_j+2,\dots,\overline p_j\}$ the optimal
cost is computed by taking the minimum of two functions,
\begin{equation}
  \label{eq:positive_update}
  C_t(\mu)=\ell(z_t, \mu) + \min
  \begin{cases}
\hat V_{t-1}+\lambda &\text{ if there is a change between $t-1$ and $t$,}\\
C_{t-1}(\mu) & \text{ if the change was before that.}
  \end{cases}
\end{equation}

\subsection{Pseudocode}

\begin{algorithm}[H]
\begin{algorithmic}[1]
\STATE Input: data $\mathbf z\in\mathbb R^d$, 
non-negative penalty $\lambda\in\RR_+$,
sorted labels $(\underline p_j, \overline p_j, c_j)\in R$.
\STATE Output: optimal cost $\hat{\mathbf C}\in\mathbb R^d$,
mean $\mathbf m\in\mathbb R^d$,
previous segment end $\mathbf T\in\{1,\dots,d\}^d$. 
\STATE $j\gets 1$ // label counter
\STATE $\text{labelType}\gets\text{unlabeled}$
\STATE for $t$ from $1$ to $d$:
\begin{ALC@g}
  \STATE if $t==1$:
  \begin{ALC@g}
    \STATE $\text{cost}\gets 0$
  \end{ALC@g}
  \STATE else if $\text{labelType}==0$:
  \begin{ALC@g}
    \STATE $\text{cost}\gets\text{prev\_cost}$
  \end{ALC@g}
  \STATE else if $\text{labelType}==1$:
  \begin{ALC@g}
    \STATE $\text{change\_cost}\gets \text{MinPiece}(V) + \lambda$
    \STATE if $t==\underline p_j+1$:
    \begin{ALC@g}
      \STATE $\text{cost}\gets\text{change\_cost}$
    \end{ALC@g}
    \STATE else:
    \begin{ALC@g}
      \STATE $\text{cost}\gets\text{MinOfTwo}(
      \text{change\_cost}, \text{prev\_cost})$
    \end{ALC@g}
    \STATE $V$ += $\text{CostFun}(z_t)$
  \end{ALC@g}
  \STATE else if $\text{labelType}==\text{unlabeled}$:
  \begin{ALC@g}
    \STATE $\text{change\_cost}\gets\text{MinPiece}(\text{cost}) + \lambda$
    \STATE $\text{cost}\gets\text{MinOfTwo}( 
    \text{change\_cost}, \text{prev\_cost})$
  \end{ALC@g}
  \STATE $\text{cost}$ += $\text{CostFun}(z_t)$
  \STATE if $t==\overline p_j$: // what update rule should we use next?
  \begin{ALC@g}
    \STATE $\text{labelType}\gets \text{unlabeled}$
    \STATE $j++$
  \end{ALC@g}
  \STATE if $t==\underline p_j$:
  \begin{ALC@g}
    \STATE $\text{labelType}\gets c_j$
    \STATE if $\text{labelType}==1$:
    \begin{ALC@g}
      \STATE $V\gets \text{cost}$
    \end{ALC@g}
  \end{ALC@g}
  \STATE $\hat C_t, m_t, T_t\gets \text{Minimize}(\text{cost})$
  \STATE $\text{prev\_cost}\gets\text{cost}$
\end{ALC@g}
\caption{\label{algo:LabeledFPOP}Labeled Functional Pruning Optimal
  Partitioning Algorithm.}
\end{algorithmic}
\end{algorithm}

\bibliographystyle{abbrvnat}
\bibliography{refs}

\end{document}
